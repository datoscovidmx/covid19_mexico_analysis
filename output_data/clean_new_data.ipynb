{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produces time series files for COVID-19 (starting march 5, when mayor changes to reports were made).\n",
    "# Before judging this mess, pleace note that daily report data is very inconsistent.\n",
    "# Thus, each report is treated individually, until data reports seem stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last data with old format\n",
    "df5 = pd.read_csv('mexico-covid19-2020-04-05.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New data format starts at 2020-04-06\n",
    "df6 = pd.read_csv('../data/mexico_covid19_data/raw-mexico-covid19-2020-04-06.csv') # Date_Arrival is now removed from reports\n",
    "df6['Date_Symptoms'] = pd.to_datetime(df6.Date_Symptoms)\n",
    "df6['Date_Symptoms'] = df6['Date_Symptoms'].dt.strftime('%m-%d-%Y')\n",
    "df6['Date_Symptoms'] = df6['Date_Symptoms'].replace('NaT', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2439"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The raw files were basically converted from pdf to csv using zamzar\n",
    "df6 = df6.drop(['Case_ID'], axis=1) # Remove this column to merge\n",
    "df6['Origin'].fillna('Contacto', inplace=True) # New data doesn't specify but we'll assume it remains by contact unless otherwise specified\n",
    "df6.index = np.arange(1, (len(df6)+1)) # New index that doesn't start from 0\n",
    "df6 = df6.reset_index() # Add index to columns\n",
    "df6 = df6.rename(columns={'index':'Case_ID'}) # Rename index\n",
    "len(df6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2439"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/19125091/pandas-merge-how-to-avoid-duplicating-columns\n",
    "df6 = df6.merge(df5, on='Case_ID', left_index=True, right_index=True, how='outer', suffixes=('', '_y')) # Match for confirmed dates from previous report\n",
    "# https://stackoverflow.com/questions/19071199/drop-columns-whose-name-contains-a-specific-string-from-pandas-dataframe\n",
    "df6 = df6.loc[:,~df6.columns.str.contains('_y', case=False)] # Drop suffix\n",
    "len(df6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of new cases should be:\n",
    "len(df6) - len(df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case_ID</th>\n",
       "      <th>Region</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Date_Symptoms</th>\n",
       "      <th>Tested</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Date_Arrival</th>\n",
       "      <th>Date_Confirmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AGUASCALIENTES</td>\n",
       "      <td>F</td>\n",
       "      <td>31</td>\n",
       "      <td>03-23-2020</td>\n",
       "      <td>Confirmado</td>\n",
       "      <td>Contacto</td>\n",
       "      <td>02-22-2020</td>\n",
       "      <td>02-27-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>M</td>\n",
       "      <td>21</td>\n",
       "      <td>03-20-2020</td>\n",
       "      <td>Confirmado</td>\n",
       "      <td>Contacto</td>\n",
       "      <td>02-21-2020</td>\n",
       "      <td>02-28-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>COAHUILA</td>\n",
       "      <td>M</td>\n",
       "      <td>40</td>\n",
       "      <td>03-25-2020</td>\n",
       "      <td>Confirmado</td>\n",
       "      <td>Contacto</td>\n",
       "      <td>02-22-2020</td>\n",
       "      <td>02-29-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>CHIHUAHUA</td>\n",
       "      <td>M</td>\n",
       "      <td>27</td>\n",
       "      <td>03-19-2020</td>\n",
       "      <td>Confirmado</td>\n",
       "      <td>Contacto</td>\n",
       "      <td>02-25-2020</td>\n",
       "      <td>02-29-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>SONORA</td>\n",
       "      <td>F</td>\n",
       "      <td>45</td>\n",
       "      <td>03-15-2020</td>\n",
       "      <td>Confirmado</td>\n",
       "      <td>Contacto</td>\n",
       "      <td>02-25-2020</td>\n",
       "      <td>03-01-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2434</td>\n",
       "      <td>2435</td>\n",
       "      <td>QUINTANA ROO</td>\n",
       "      <td>F</td>\n",
       "      <td>30</td>\n",
       "      <td>03-29-2020</td>\n",
       "      <td>Confirmado</td>\n",
       "      <td>Contacto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2435</td>\n",
       "      <td>2436</td>\n",
       "      <td>JALISCO</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>03-17-2020</td>\n",
       "      <td>Confirmado</td>\n",
       "      <td>Estados</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2436</td>\n",
       "      <td>2437</td>\n",
       "      <td>JALISCO</td>\n",
       "      <td>F</td>\n",
       "      <td>34</td>\n",
       "      <td>03-21-2020</td>\n",
       "      <td>Confirmado</td>\n",
       "      <td>Contacto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2437</td>\n",
       "      <td>2438</td>\n",
       "      <td>TABASCO</td>\n",
       "      <td>M</td>\n",
       "      <td>59</td>\n",
       "      <td>03-26-2020</td>\n",
       "      <td>Confirmado</td>\n",
       "      <td>Contacto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2438</td>\n",
       "      <td>2439</td>\n",
       "      <td>TABASCO</td>\n",
       "      <td>F</td>\n",
       "      <td>24</td>\n",
       "      <td>03-15-2020</td>\n",
       "      <td>Confirmado</td>\n",
       "      <td>Contacto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2439 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Case_ID          Region Sex  Age Date_Symptoms      Tested    Origin  \\\n",
       "0           1  AGUASCALIENTES   F   31    03-23-2020  Confirmado  Contacto   \n",
       "1           2          MEXICO   M   21    03-20-2020  Confirmado  Contacto   \n",
       "2           3        COAHUILA   M   40    03-25-2020  Confirmado  Contacto   \n",
       "3           4       CHIHUAHUA   M   27    03-19-2020  Confirmado  Contacto   \n",
       "4           5          SONORA   F   45    03-15-2020  Confirmado  Contacto   \n",
       "...       ...             ...  ..  ...           ...         ...       ...   \n",
       "2434     2435    QUINTANA ROO   F   30    03-29-2020  Confirmado  Contacto   \n",
       "2435     2436         JALISCO   M   25    03-17-2020  Confirmado   Estados   \n",
       "2436     2437         JALISCO   F   34    03-21-2020  Confirmado  Contacto   \n",
       "2437     2438         TABASCO   M   59    03-26-2020  Confirmado  Contacto   \n",
       "2438     2439         TABASCO   F   24    03-15-2020  Confirmado  Contacto   \n",
       "\n",
       "     Date_Arrival Date_Confirmed  \n",
       "0      02-22-2020     02-27-2020  \n",
       "1      02-21-2020     02-28-2020  \n",
       "2      02-22-2020     02-29-2020  \n",
       "3      02-25-2020     02-29-2020  \n",
       "4      02-25-2020     03-01-2020  \n",
       "...           ...            ...  \n",
       "2434          NaN            NaN  \n",
       "2435          NaN            NaN  \n",
       "2436          NaN            NaN  \n",
       "2437          NaN            NaN  \n",
       "2438          NaN            NaN  \n",
       "\n",
       "[2439 rows x 9 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/37313691/how-to-remove-a-pandas-dataframe-from-another-dataframe\n",
    "out6 = df6.append(df5) # The resulting length after this opreration should match the new cases!\n",
    "out6 = out6[~out6.index.duplicated(keep=False)] # Had to test several times to guess...\n",
    "out6.Date_Confirmed = out6.Date_Confirmed.fillna('04-06-2020')\n",
    "out6 = pd.concat([df5, out6], sort=True)\n",
    "out6[['Case_ID', 'Age']] = out6[['Case_ID', 'Age']].astype(int)\n",
    "out6 = out6[['Case_ID','Region','Sex','Age','Date_Symptoms','Tested','Origin','Date_Arrival','Date_Confirmed']]\n",
    "out6.to_csv('mexico-covid19-2020-04-06.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the analysis above we can deduce that the new data is probably just being appended to the end of the last report (?)\n",
    "# Will do the same method for the next few days/week, and if it remains consistent, will make it functional!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2020-04-07\n",
    "df7 = pd.read_csv('../data/mexico_covid19_data/raw-mexico-covid19-2020-04-07.csv')\n",
    "df7['Date_Symptoms'] = pd.to_datetime(df7.Date_Symptoms)\n",
    "df7['Date_Symptoms'] = df7['Date_Symptoms'].dt.strftime('%m-%d-%Y')\n",
    "df7['Date_Symptoms'] = df7['Date_Symptoms'].replace('NaT', '')\n",
    "\n",
    "out7 = df7.append(out6) # The resulting length after this opreration should match the new cases!\n",
    "out7 = out7[~out7.index.duplicated(keep=False)] # Had to test several times to guess...\n",
    "out7.Date_Confirmed = out7.Date_Confirmed.fillna('04-07-2020')\n",
    "out7 = pd.concat([out6, out7], sort=True) # Use last df in memory, sorry\n",
    "out7.Case_ID = pd.to_numeric(out7.Case_ID, errors='coerce').fillna(0).astype(np.int64) #https://stackoverflow.com/questions/42719749/pandas-convert-string-to-int\n",
    "out7.Age = pd.to_numeric(out7.Age, errors='coerce').fillna(0).astype(np.int64)\n",
    "out7 = out7[['Case_ID','Region','Sex','Age','Date_Symptoms','Tested','Origin','Date_Arrival','Date_Confirmed']]\n",
    "out7.to_csv('mexico-covid19-2020-04-07.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2020-04-08\n",
    "df8 = pd.read_csv('../data/mexico_covid19_data/raw-mexico-covid19-2020-04-08.csv') # Origin is now removed from the daily report\n",
    "df8['Date_Symptoms'] = pd.to_datetime(df8.Date_Symptoms)\n",
    "df8['Date_Symptoms'] = df8['Date_Symptoms'].dt.strftime('%m-%d-%Y')\n",
    "df8['Date_Symptoms'] = df8['Date_Symptoms'].replace('NaT', '')\n",
    "\n",
    "df8 = df8.merge(df7, on='Case_ID', left_index=True, right_index=True, how='outer', suffixes=('', '_y')) # Match deprecated columns from last report\n",
    "df8 = df8.loc[:,~df8.columns.str.contains('_y', case=False)] # Drop suffix\n",
    "df8['Origin'].fillna('Contacto', inplace=True) # Fill after merge\n",
    "\n",
    "out8 = df8.append(out7) # The resulting length after this opreration should match the new cases!\n",
    "out8 = out8[~out8.index.duplicated(keep=False)] # Had to test several times to guess...\n",
    "out8.Date_Confirmed = out8.Date_Confirmed.fillna('04-08-2020')\n",
    "out8 = pd.concat([out7, out8], sort=True) # Use last df in memory, sorry\n",
    "out8.Case_ID = pd.to_numeric(out8.Case_ID, errors='coerce').fillna(0).astype(np.int64)\n",
    "out8.Age = pd.to_numeric(out8.Age, errors='coerce').fillna(0).astype(np.int64)\n",
    "out8 = out8[['Case_ID','Region','Sex','Age','Date_Symptoms','Tested','Origin','Date_Arrival','Date_Confirmed']]\n",
    "out8.to_csv('mexico-covid19-2020-04-08.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2020-04-09\n",
    "df9 = pd.read_csv('../data/mexico_covid19_data/raw-mexico-covid19-2020-04-09.csv') # Origin is now removed from the daily report\n",
    "df9['Date_Symptoms'] = pd.to_datetime(df9.Date_Symptoms)\n",
    "df9['Date_Symptoms'] = df9['Date_Symptoms'].dt.strftime('%m-%d-%Y')\n",
    "df9['Date_Symptoms'] = df9['Date_Symptoms'].replace('NaT', '')\n",
    "\n",
    "df9 = df9.merge(df8, on='Case_ID', left_index=True, right_index=True, how='outer', suffixes=('', '_y')) # Match deprecated columns from last report\n",
    "df9 = df9.loc[:,~df9.columns.str.contains('_y', case=False)] # Drop suffix\n",
    "df9['Origin'].fillna('Contacto', inplace=True) # Fill after merge\n",
    "\n",
    "out9 = df9.append(out8)\n",
    "out9 = out9[~out9.index.duplicated(keep=False)]\n",
    "out9.Date_Confirmed = out9.Date_Confirmed.fillna('04-09-2020')\n",
    "out9 = pd.concat([out8, out9], sort=True) # Use last df in memory, sorry\n",
    "out9.to_csv('mexico-covid19-2020-04-09.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2020-04-10\n",
    "df10 = pd.read_csv('../data/mexico_covid19_data/raw-mexico-covid19-2020-04-10.csv') # Origin is now removed from the daily report\n",
    "df10['Date_Symptoms'] = pd.to_datetime(df10.Date_Symptoms)\n",
    "df10['Date_Symptoms'] = df10['Date_Symptoms'].dt.strftime('%m-%d-%Y')\n",
    "df10['Date_Symptoms'] = df10['Date_Symptoms'].replace('NaT', '')\n",
    "\n",
    "df10 = df10.merge(df9, on='Case_ID', left_index=True, right_index=True, how='outer', suffixes=('', '_y')) # Match deprecated columns from last report\n",
    "df10 = df10.loc[:,~df10.columns.str.contains('_y', case=False)] # Drop suffix\n",
    "df10['Origin'].fillna('Contacto', inplace=True) # Fill after merge\n",
    "\n",
    "out10 = df10.append(out9)\n",
    "out10 = out10[~out10.index.duplicated(keep=False)]\n",
    "out10.Date_Confirmed = out10.Date_Confirmed.fillna('04-10-2020')\n",
    "out10 = pd.concat([out9, out10], sort=True) # Use last df in memory, sorry\n",
    "out10.to_csv('mexico-covid19-2020-04-10.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2020-04-11\n",
    "df11 = pd.read_csv('../data/mexico_covid19_data/raw-mexico-covid19-2020-04-11.csv') # Origin is now removed from the daily report\n",
    "df11['Date_Symptoms'] = pd.to_datetime(df11.Date_Symptoms)\n",
    "df11['Date_Symptoms'] = df11['Date_Symptoms'].dt.strftime('%m-%d-%Y')\n",
    "df11['Date_Symptoms'] = df11['Date_Symptoms'].replace('NaT', '')\n",
    "\n",
    "df11 = df11.merge(df10, on='Case_ID', left_index=True, right_index=True, how='outer', suffixes=('', '_y')) # Match deprecated columns from last report\n",
    "df11 = df11.loc[:,~df11.columns.str.contains('_y', case=False)] # Drop suffix\n",
    "df11['Origin'].fillna('Contacto', inplace=True) # Fill after merge\n",
    "\n",
    "out11 = df11.append(out10)\n",
    "out11 = out11[~out11.index.duplicated(keep=False)]\n",
    "out11.Date_Confirmed = out11.Date_Confirmed.fillna('04-11-2020')\n",
    "out11 = pd.concat([out10, out11], sort=True) # Use last df in memory, sorry\n",
    "out11.to_csv('mexico-covid19-2020-04-11.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2020-04-12\n",
    "df12 = pd.read_csv('../data/mexico_covid19_data/raw-mexico-covid19-2020-04-12.csv') # Origin is now removed from the daily report\n",
    "df12['Date_Symptoms'] = pd.to_datetime(df12.Date_Symptoms)\n",
    "df12['Date_Symptoms'] = df12['Date_Symptoms'].dt.strftime('%m-%d-%Y')\n",
    "df12['Date_Symptoms'] = df12['Date_Symptoms'].replace('NaT', '')\n",
    "\n",
    "df12 = df12.merge(df11, on='Case_ID', left_index=True, right_index=True, how='outer', suffixes=('', '_y')) # Match deprecated columns from last report\n",
    "df12 = df12.loc[:,~df12.columns.str.contains('_y', case=False)] # Drop suffix\n",
    "df12['Origin'].fillna('Contacto', inplace=True) # Fill after merge\n",
    "\n",
    "out12 = df12.append(out11)\n",
    "out12 = out12[~out12.index.duplicated(keep=False)]\n",
    "out12.Date_Confirmed = out12.Date_Confirmed.fillna('04-12-2020')\n",
    "out12 = pd.concat([out11, out12], sort=True) # Use last df in memory, sorry\n",
    "out12.to_csv('mexico-covid19-2020-04-12.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2020-04-13\n",
    "df13 = pd.read_csv('../data/mexico_covid19_data/raw-mexico-covid19-2020-04-13.csv') # Origin is now removed from the daily report\n",
    "df13['Date_Symptoms'] = pd.to_datetime(df13.Date_Symptoms)\n",
    "df13['Date_Symptoms'] = df13['Date_Symptoms'].dt.strftime('%m-%d-%Y')\n",
    "df13['Date_Symptoms'] = df13['Date_Symptoms'].replace('NaT', '')\n",
    "\n",
    "df13 = df13.merge(df12, on='Case_ID', left_index=True, right_index=True, how='outer', suffixes=('', '_y')) # Match deprecated columns from last report\n",
    "df13 = df13.loc[:,~df13.columns.str.contains('_y', case=False)] # Drop suffix\n",
    "df13['Origin'].fillna('Contacto', inplace=True) # Fill after merge\n",
    "\n",
    "out13 = df13.append(out12)\n",
    "out13 = out13[~out13.index.duplicated(keep=False)]\n",
    "out13.Date_Confirmed = out13.Date_Confirmed.fillna('04-13-2020')\n",
    "out13 = pd.concat([out12, out13], sort=True) # Use last df in memory, sorry\n",
    "out13.to_csv('mexico-covid19-2020-04-13.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2020-04-14\n",
    "df14 = pd.read_csv('../data/mexico_covid19_data/raw-mexico-covid19-2020-04-14.csv') # Origin is now removed from the daily report\n",
    "df14['Date_Symptoms'] = pd.to_datetime(df14.Date_Symptoms)\n",
    "df14['Date_Symptoms'] = df14['Date_Symptoms'].dt.strftime('%m-%d-%Y')\n",
    "df14['Date_Symptoms'] = df14['Date_Symptoms'].replace('NaT', '')\n",
    "\n",
    "df14 = df14.merge(df13, on='Case_ID', left_index=True, right_index=True, how='outer', suffixes=('', '_y')) # Match deprecated columns from last report\n",
    "df14 = df14.loc[:,~df14.columns.str.contains('_y', case=False)] # Drop suffix\n",
    "df14['Origin'].fillna('Contacto', inplace=True) # Fill after merge\n",
    "\n",
    "out14 = df14.append(out13)\n",
    "out14 = out14[~out14.index.duplicated(keep=False)]\n",
    "out14.Date_Confirmed = out14.Date_Confirmed.fillna('04-14-2020')\n",
    "out14 = pd.concat([out13, out14], sort=True) # Use last df in memory, sorry\n",
    "out14.to_csv('mexico-covid19-2020-04-14.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2020-04-15\n",
    "df15 = pd.read_csv('../data/mexico_covid19_data/raw-mexico-covid19-2020-04-15.csv') # Origin is now removed from the daily report\n",
    "df15['Date_Symptoms'] = pd.to_datetime(df15.Date_Symptoms)\n",
    "df15['Date_Symptoms'] = df15['Date_Symptoms'].dt.strftime('%m-%d-%Y')\n",
    "df15['Date_Symptoms'] = df15['Date_Symptoms'].replace('NaT', '')\n",
    "\n",
    "df15 = df15.merge(df13, on='Case_ID', left_index=True, right_index=True, how='outer', suffixes=('', '_y')) # Match deprecated columns from last report\n",
    "df15 = df15.loc[:,~df15.columns.str.contains('_y', case=False)] # Drop suffix\n",
    "df15['Origin'].fillna('Contacto', inplace=True) # Fill after merge\n",
    "\n",
    "out15 = df15.append(out13)\n",
    "out15 = out15[~out15.index.duplicated(keep=False)]\n",
    "out15.Date_Confirmed = out15.Date_Confirmed.fillna('04-15-2020')\n",
    "out15 = pd.concat([out14, out15], sort=True) # Use last df in memory, sorry\n",
    "out15.to_csv('mexico-covid19-2020-04-15.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
